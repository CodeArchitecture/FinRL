{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/CodeArchitecture/FinRL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/kaggle/working/FinRL')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "08159edd-35c4-4dd6-8462-3e64f26d71f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../FinRL\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RtUc_ofKmpdy"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "2a4358a8-0656-4d5e-dc3e-b693cae3c5b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2020-07-31'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py, TRAIN_START_DATE is a string\n",
    "TRAIN_START_DATE\n",
    "# from config.py, TRAIN_END_DATE is a string\n",
    "TRAIN_END_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FUnY8WEfLq3C"
   },
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2010-01-01'\n",
    "TRAIN_END_DATE = '2021-10-01'\n",
    "TRADE_START_DATE = '2021-10-01'\n",
    "TRADE_END_DATE = '2023-03-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "a9d4f123-e338-4eca-feb1-358503317d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (97013, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "e302049c-08e1-4ff0-ce60-7faf71776eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
     ]
    }
   ],
   "source": [
    "print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "81ee90f7-c290-40d9-81a0-8b771f3699ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97013, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "b64d30ce-6f5a-461e-c6fe-1baee4642b4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5e0f2423-743c-49d5-b435-c73c39a5d717\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>6.505280</td>\n",
       "      <td>493729600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>56.630001</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>56.560001</td>\n",
       "      <td>42.888943</td>\n",
       "      <td>5277400</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>40.810001</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>40.389999</td>\n",
       "      <td>33.675961</td>\n",
       "      <td>6894300</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>55.720001</td>\n",
       "      <td>56.389999</td>\n",
       "      <td>54.799999</td>\n",
       "      <td>43.777538</td>\n",
       "      <td>6186700</td>\n",
       "      <td>BA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>57.650002</td>\n",
       "      <td>59.189999</td>\n",
       "      <td>57.509998</td>\n",
       "      <td>41.156910</td>\n",
       "      <td>7325600</td>\n",
       "      <td>CAT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e0f2423-743c-49d5-b435-c73c39a5d717')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5e0f2423-743c-49d5-b435-c73c39a5d717 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5e0f2423-743c-49d5-b435-c73c39a5d717');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         date       open       high        low      close     volume   tic  \\\n",
       "0  2010-01-04   7.622500   7.660714   7.585000   6.505280  493729600  AAPL   \n",
       "1  2010-01-04  56.630001  57.869999  56.560001  42.888943    5277400  AMGN   \n",
       "2  2010-01-04  40.810001  41.099998  40.389999  33.675961    6894300   AXP   \n",
       "3  2010-01-04  55.720001  56.389999  54.799999  43.777538    6186700    BA   \n",
       "4  2010-01-04  57.650002  59.189999  57.509998  41.156910    7325600   CAT   \n",
       "\n",
       "   day  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "6e4b4cc7-593b-4403-eb2a-828f55ed5a89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (3310, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = INDICATORS,\n",
    "                    use_vix=True,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "grvhGJJII3Xn",
    "outputId": "627d411c-d197-4019-8940-4d88a68dbfc9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f0f7393d-e1de-4655-ae33-9b9d0e5bdb7c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>6.505280</td>\n",
       "      <td>493729600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.505280</td>\n",
       "      <td>6.505280</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>56.630001</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>56.560001</td>\n",
       "      <td>42.888943</td>\n",
       "      <td>5277400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.888943</td>\n",
       "      <td>42.888943</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>AXP</td>\n",
       "      <td>40.810001</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>40.389999</td>\n",
       "      <td>33.675961</td>\n",
       "      <td>6894300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.675961</td>\n",
       "      <td>33.675961</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>BA</td>\n",
       "      <td>55.720001</td>\n",
       "      <td>56.389999</td>\n",
       "      <td>54.799999</td>\n",
       "      <td>43.777538</td>\n",
       "      <td>6186700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.777538</td>\n",
       "      <td>43.777538</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>CAT</td>\n",
       "      <td>57.650002</td>\n",
       "      <td>59.189999</td>\n",
       "      <td>57.509998</td>\n",
       "      <td>41.156910</td>\n",
       "      <td>7325600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>41.156910</td>\n",
       "      <td>41.156910</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>CRM</td>\n",
       "      <td>18.652500</td>\n",
       "      <td>18.882500</td>\n",
       "      <td>18.547501</td>\n",
       "      <td>18.705000</td>\n",
       "      <td>7906000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.705000</td>\n",
       "      <td>18.705000</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>24.110001</td>\n",
       "      <td>24.840000</td>\n",
       "      <td>24.010000</td>\n",
       "      <td>17.394125</td>\n",
       "      <td>59853700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17.394125</td>\n",
       "      <td>17.394125</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>CVX</td>\n",
       "      <td>78.199997</td>\n",
       "      <td>79.199997</td>\n",
       "      <td>78.160004</td>\n",
       "      <td>46.851871</td>\n",
       "      <td>10173800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>46.851871</td>\n",
       "      <td>46.851871</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>DIS</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>31.870001</td>\n",
       "      <td>27.933922</td>\n",
       "      <td>13700400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.933922</td>\n",
       "      <td>27.933922</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>GS</td>\n",
       "      <td>170.050003</td>\n",
       "      <td>174.250000</td>\n",
       "      <td>169.509995</td>\n",
       "      <td>139.862900</td>\n",
       "      <td>9135000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.526809</td>\n",
       "      <td>6.494997</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>139.862900</td>\n",
       "      <td>139.862900</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0f7393d-e1de-4655-ae33-9b9d0e5bdb7c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f0f7393d-e1de-4655-ae33-9b9d0e5bdb7c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f0f7393d-e1de-4655-ae33-9b9d0e5bdb7c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         date   tic        open        high         low       close  \\\n",
       "0  2010-01-04  AAPL    7.622500    7.660714    7.585000    6.505280   \n",
       "1  2010-01-04  AMGN   56.630001   57.869999   56.560001   42.888943   \n",
       "2  2010-01-04   AXP   40.810001   41.099998   40.389999   33.675961   \n",
       "3  2010-01-04    BA   55.720001   56.389999   54.799999   43.777538   \n",
       "4  2010-01-04   CAT   57.650002   59.189999   57.509998   41.156910   \n",
       "5  2010-01-04   CRM   18.652500   18.882500   18.547501   18.705000   \n",
       "6  2010-01-04  CSCO   24.110001   24.840000   24.010000   17.394125   \n",
       "7  2010-01-04   CVX   78.199997   79.199997   78.160004   46.851871   \n",
       "8  2010-01-04   DIS   32.500000   32.750000   31.870001   27.933922   \n",
       "9  2010-01-04    GS  170.050003  174.250000  169.509995  139.862900   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  493729600.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "1    5277400.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "2    6894300.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "3    6186700.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "4    7325600.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "5    7906000.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "6   59853700.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "7   10173800.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "8   13700400.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "9    9135000.0  0.0   0.0  6.526809  6.494997   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma        vix  turbulence  \n",
       "0      6.505280      6.505280  20.040001         0.0  \n",
       "1     42.888943     42.888943  20.040001         0.0  \n",
       "2     33.675961     33.675961  20.040001         0.0  \n",
       "3     43.777538     43.777538  20.040001         0.0  \n",
       "4     41.156910     41.156910  20.040001         0.0  \n",
       "5     18.705000     18.705000  20.040001         0.0  \n",
       "6     17.394125     17.394125  20.040001         0.0  \n",
       "7     46.851871     46.851871  20.040001         0.0  \n",
       "8     27.933922     27.933922  20.040001         0.0  \n",
       "9    139.862900    139.862900  20.040001         0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5vdORQ384Qx-"
   },
   "outputs": [],
   "source": [
    "mvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "5e364280-c418-470f-e25c-f03f56adbda7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85753\n",
      "10237\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "p52zNCOhTtLR",
    "outputId": "e205ad4d-49ad-472b-8b60-0dc14a629113"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-90f2e3b9-5218-49d2-afd3-91bb0e5df514\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>401.489990</td>\n",
       "      <td>403.489990</td>\n",
       "      <td>390.459991</td>\n",
       "      <td>383.180145</td>\n",
       "      <td>3779900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.349257</td>\n",
       "      <td>419.212249</td>\n",
       "      <td>386.863767</td>\n",
       "      <td>40.895372</td>\n",
       "      <td>-222.938263</td>\n",
       "      <td>41.980385</td>\n",
       "      <td>405.947460</td>\n",
       "      <td>405.438415</td>\n",
       "      <td>23.139999</td>\n",
       "      <td>24.871997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>V</td>\n",
       "      <td>227.580002</td>\n",
       "      <td>228.789993</td>\n",
       "      <td>222.630005</td>\n",
       "      <td>220.257767</td>\n",
       "      <td>7128500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.538726</td>\n",
       "      <td>228.639288</td>\n",
       "      <td>216.529588</td>\n",
       "      <td>44.078992</td>\n",
       "      <td>-54.614561</td>\n",
       "      <td>19.569853</td>\n",
       "      <td>224.777294</td>\n",
       "      <td>231.479429</td>\n",
       "      <td>23.139999</td>\n",
       "      <td>24.871997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>54.509998</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>49.822678</td>\n",
       "      <td>18736600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.237533</td>\n",
       "      <td>50.960816</td>\n",
       "      <td>49.550736</td>\n",
       "      <td>41.824914</td>\n",
       "      <td>-102.899147</td>\n",
       "      <td>21.682953</td>\n",
       "      <td>50.425972</td>\n",
       "      <td>50.960237</td>\n",
       "      <td>23.139999</td>\n",
       "      <td>24.871997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>48.790001</td>\n",
       "      <td>48.930000</td>\n",
       "      <td>46.919998</td>\n",
       "      <td>43.957283</td>\n",
       "      <td>6449400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.253540</td>\n",
       "      <td>48.531811</td>\n",
       "      <td>43.597245</td>\n",
       "      <td>44.613717</td>\n",
       "      <td>-107.390242</td>\n",
       "      <td>0.941150</td>\n",
       "      <td>45.886550</td>\n",
       "      <td>44.857786</td>\n",
       "      <td>23.139999</td>\n",
       "      <td>24.871997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>140.639999</td>\n",
       "      <td>141.729996</td>\n",
       "      <td>139.250000</td>\n",
       "      <td>136.672668</td>\n",
       "      <td>7485900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.561206</td>\n",
       "      <td>146.754148</td>\n",
       "      <td>136.189053</td>\n",
       "      <td>40.165800</td>\n",
       "      <td>-151.553868</td>\n",
       "      <td>45.466733</td>\n",
       "      <td>142.928735</td>\n",
       "      <td>141.825645</td>\n",
       "      <td>23.139999</td>\n",
       "      <td>24.871997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90f2e3b9-5218-49d2-afd3-91bb0e5df514')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-90f2e3b9-5218-49d2-afd3-91bb0e5df514 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-90f2e3b9-5218-49d2-afd3-91bb0e5df514');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            date  tic        open        high         low       close  \\\n",
       "2956  2021-09-30  UNH  401.489990  403.489990  390.459991  383.180145   \n",
       "2956  2021-09-30    V  227.580002  228.789993  222.630005  220.257767   \n",
       "2956  2021-09-30   VZ   54.500000   54.509998   54.000000   49.822678   \n",
       "2956  2021-09-30  WBA   48.790001   48.930000   46.919998   43.957283   \n",
       "2956  2021-09-30  WMT  140.639999  141.729996  139.250000  136.672668   \n",
       "\n",
       "          volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "2956   3779900.0  3.0 -4.349257  419.212249  386.863767  40.895372   \n",
       "2956   7128500.0  3.0 -1.538726  228.639288  216.529588  44.078992   \n",
       "2956  18736600.0  3.0 -0.237533   50.960816   49.550736  41.824914   \n",
       "2956   6449400.0  3.0 -0.253540   48.531811   43.597245  44.613717   \n",
       "2956   7485900.0  3.0 -1.561206  146.754148  136.189053  40.165800   \n",
       "\n",
       "          cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "2956 -222.938263  41.980385    405.947460    405.438415  23.139999   24.871997  \n",
       "2956  -54.614561  19.569853    224.777294    231.479429  23.139999   24.871997  \n",
       "2956 -102.899147  21.682953     50.425972     50.960237  23.139999   24.871997  \n",
       "2956 -107.390242   0.941150     45.886550     44.857786  23.139999   24.871997  \n",
       "2956 -151.553868  45.466733    142.928735    141.825645  23.139999   24.871997  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "b23fd388-7411-4c78-8ebf-eb33df9b40a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-10ebda38-ede1-43c1-b44d-c81afef0afd2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>141.899994</td>\n",
       "      <td>142.919998</td>\n",
       "      <td>139.110001</td>\n",
       "      <td>141.404266</td>\n",
       "      <td>94639600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.703487</td>\n",
       "      <td>155.382845</td>\n",
       "      <td>137.132192</td>\n",
       "      <td>46.927735</td>\n",
       "      <td>-142.190143</td>\n",
       "      <td>41.749873</td>\n",
       "      <td>147.171798</td>\n",
       "      <td>146.269416</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>213.589996</td>\n",
       "      <td>214.610001</td>\n",
       "      <td>210.800003</td>\n",
       "      <td>203.845886</td>\n",
       "      <td>2629400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.097331</td>\n",
       "      <td>212.767983</td>\n",
       "      <td>199.379593</td>\n",
       "      <td>40.408568</td>\n",
       "      <td>-96.756949</td>\n",
       "      <td>36.189244</td>\n",
       "      <td>208.480831</td>\n",
       "      <td>217.103342</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>168.500000</td>\n",
       "      <td>175.119995</td>\n",
       "      <td>168.479996</td>\n",
       "      <td>170.695389</td>\n",
       "      <td>3956000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.281748</td>\n",
       "      <td>174.864263</td>\n",
       "      <td>149.785746</td>\n",
       "      <td>56.265103</td>\n",
       "      <td>117.565552</td>\n",
       "      <td>15.667511</td>\n",
       "      <td>161.812905</td>\n",
       "      <td>164.064442</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>222.850006</td>\n",
       "      <td>226.720001</td>\n",
       "      <td>220.600006</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>9113600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.730320</td>\n",
       "      <td>226.909442</td>\n",
       "      <td>205.727561</td>\n",
       "      <td>51.614047</td>\n",
       "      <td>116.649440</td>\n",
       "      <td>2.027170</td>\n",
       "      <td>217.175334</td>\n",
       "      <td>221.968500</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>192.899994</td>\n",
       "      <td>195.869995</td>\n",
       "      <td>191.240005</td>\n",
       "      <td>187.928040</td>\n",
       "      <td>3695500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.640323</td>\n",
       "      <td>205.735917</td>\n",
       "      <td>181.432778</td>\n",
       "      <td>41.999441</td>\n",
       "      <td>-112.087750</td>\n",
       "      <td>36.203176</td>\n",
       "      <td>196.993865</td>\n",
       "      <td>200.522105</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10ebda38-ede1-43c1-b44d-c81afef0afd2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-10ebda38-ede1-43c1-b44d-c81afef0afd2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-10ebda38-ede1-43c1-b44d-c81afef0afd2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         date   tic        open        high         low       close  \\\n",
       "0  2021-10-01  AAPL  141.899994  142.919998  139.110001  141.404266   \n",
       "0  2021-10-01  AMGN  213.589996  214.610001  210.800003  203.845886   \n",
       "0  2021-10-01   AXP  168.500000  175.119995  168.479996  170.695389   \n",
       "0  2021-10-01    BA  222.850006  226.720001  220.600006  226.000000   \n",
       "0  2021-10-01   CAT  192.899994  195.869995  191.240005  187.928040   \n",
       "\n",
       "       volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
       "0  94639600.0  4.0 -1.703487  155.382845  137.132192  46.927735 -142.190143   \n",
       "0   2629400.0  4.0 -3.097331  212.767983  199.379593  40.408568  -96.756949   \n",
       "0   3956000.0  4.0  2.281748  174.864263  149.785746  56.265103  117.565552   \n",
       "0   9113600.0  4.0  0.730320  226.909442  205.727561  51.614047  116.649440   \n",
       "0   3695500.0  4.0 -3.640323  205.735917  181.432778  41.999441 -112.087750   \n",
       "\n",
       "       dx_30  close_30_sma  close_60_sma   vix  turbulence  \n",
       "0  41.749873    147.171798    146.269416  21.1  120.122917  \n",
       "0  36.189244    208.480831    217.103342  21.1  120.122917  \n",
       "0  15.667511    161.812905    164.064442  21.1  120.122917  \n",
       "0   2.027170    217.175334    221.968500  21.1  120.122917  \n",
       "0  36.203176    196.993865    200.522105  21.1  120.122917  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "a9353918-3ff6-4179-e645-1e6c664b4506"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "687c0ea8-d3d9-460a-d104-d088db843e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "ad3318cc-a3c6-41ee-cdeb-a4eb317e33bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True\n",
    "\n",
    "TIMESTEPS = [50000,50000,50000,50000,50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Agent 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "6da723f6-2f9b-4d76-8872-328ef56dadfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to results/a2c\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "a919c17f-f561-45fa-8b55-3c996811a63e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 42        |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -59.6     |\n",
      "|    reward             | 1.0448978 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 3.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0.105     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -66.6     |\n",
      "|    reward             | 0.9660278 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 52         |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -183       |\n",
      "|    reward             | -2.3506932 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 33.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 106       |\n",
      "|    reward             | 1.2101291 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 8.09      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 54.7     |\n",
      "|    reward             | -2.13098 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 6.34     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 24.6      |\n",
      "|    reward             | 0.3384871 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.374     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 56         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 0.997      |\n",
      "|    reward             | 0.25741363 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.106      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 58         |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 10.1       |\n",
      "|    reward             | 0.31647584 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 83.2     |\n",
      "|    reward             | 3.478022 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -287      |\n",
      "|    reward             | 5.5255313 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 108       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 60         |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 238        |\n",
      "|    reward             | 0.19302495 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 66.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 60         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 98         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0.235      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -42.8      |\n",
      "|    reward             | -1.7718072 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.57       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | 0.53076863 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 16         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0.0758    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 127       |\n",
      "|    reward             | 1.5990568 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 12        |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 61          |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.6       |\n",
      "|    explained_variance | 0.0174      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 43.1        |\n",
      "|    reward             | -0.78735256 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.28        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 130        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -62.8      |\n",
      "|    reward             | -3.9351795 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 10.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | -0.00197  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 863       |\n",
      "|    reward             | 15.370292 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 432       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | -0.0663    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -105       |\n",
      "|    reward             | 0.48280737 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 9.89       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 60         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -113       |\n",
      "|    reward             | 0.26411447 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 10.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 163        |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | -0.227     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 54.7       |\n",
      "|    reward             | 0.29459578 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.48       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | -0.00482  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -41.9     |\n",
      "|    reward             | 1.0095307 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.75      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | -0.00284   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 35.1       |\n",
      "|    reward             | -1.4420356 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.64       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 0.0362    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 307       |\n",
      "|    reward             | 0.8030618 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 58.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | -0.0606    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | 67.6       |\n",
      "|    reward             | 0.21994063 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.12       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | -15.3      |\n",
      "|    reward             | 0.06845646 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.694      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 62          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 43.1        |\n",
      "|    reward             | -0.10593105 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 62          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | -3.26       |\n",
      "|    reward             | -0.76443106 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.466       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -84.6     |\n",
      "|    reward             | 1.0745509 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.8       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 61          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 489         |\n",
      "|    reward             | -0.22960186 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 203         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | -0.14      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -11.4      |\n",
      "|    reward             | -0.5049368 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.505      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 249       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -99.8     |\n",
      "|    reward             | 0.4471302 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 255       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 178       |\n",
      "|    reward             | 1.2417748 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 26.9      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 61          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -31.2       |\n",
      "|    reward             | 0.031511165 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.802       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -148      |\n",
      "|    reward             | 4.5629287 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 53.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 280        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 67.3       |\n",
      "|    reward             | -2.2339873 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 47.8       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 289       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0.0153    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -0.856    |\n",
      "|    reward             | 0.2917868 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.0752    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 62          |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | 18.7        |\n",
      "|    reward             | 0.030824203 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | -70.4      |\n",
      "|    reward             | -0.2733519 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 8.28       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 313        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 17.6       |\n",
      "|    reward             | 0.17095129 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.764      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 322        |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -1.15e+03  |\n",
      "|    reward             | -1.5058991 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 666        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 329        |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 309        |\n",
      "|    reward             | -2.3266535 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 56.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | -18.2      |\n",
      "|    reward             | -1.3121804 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.717      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 345       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 44.2      |\n",
      "|    reward             | 0.3224479 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.09      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 355        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 12         |\n",
      "|    reward             | -3.8448317 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.994      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 362       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42       |\n",
      "|    explained_variance | -0.000148 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 36.3      |\n",
      "|    reward             | 3.5755417 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.65      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 62          |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 370         |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | 213         |\n",
      "|    reward             | -0.56036687 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 51          |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 377        |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | 197        |\n",
      "|    reward             | -6.2142897 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 33.6       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 62          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | 1.84        |\n",
      "|    reward             | -0.40594038 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 62          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | 17.3        |\n",
      "|    reward             | -0.11167521 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 402       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | 0.00414   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -227      |\n",
      "|    reward             | 0.8466212 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 28.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 62          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 410         |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.1       |\n",
      "|    explained_variance | 0.00168     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 294         |\n",
      "|    reward             | -0.38854757 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 46.4        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 418       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 206       |\n",
      "|    reward             | 0.5009032 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 51.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 427        |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.1      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | 893        |\n",
      "|    reward             | -3.5664086 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 437        |\n",
      "--------------------------------------\n",
      "day: 2956, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6234728.14\n",
      "total_reward: 5234728.14\n",
      "total_cost: 26372.84\n",
      "total_trades: 46613\n",
      "Sharpe: 0.901\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 61          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 437         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -91.9       |\n",
      "|    reward             | -0.70080554 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 4.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 61          |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 445         |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42         |\n",
      "|    explained_variance | -0.00337    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | 113         |\n",
      "|    reward             | -0.49402773 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.68        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 452        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 81.2       |\n",
      "|    reward             | 0.93675065 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 6.81       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 460       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 35.6      |\n",
      "|    reward             | 1.6135367 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.44      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 62         |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 466        |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | 344        |\n",
      "|    reward             | -3.7252083 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 71.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 480       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | 7.75e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -243      |\n",
      "|    reward             | -5.271583 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 37.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 60         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 494        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | -124       |\n",
      "|    reward             | 0.39913905 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 9.03       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 60          |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 501         |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | 39.8        |\n",
      "|    reward             | -0.43069157 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 60         |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 509        |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0.0522     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | -163       |\n",
      "|    reward             | -2.9920352 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 37.3       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 60          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 518         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | -25.6       |\n",
      "|    reward             | -0.82676774 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 527       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -167      |\n",
      "|    reward             | 2.0950716 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 20.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 60         |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 534        |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | 449        |\n",
      "|    reward             | -3.8287592 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 110        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 60         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 541        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -87.1      |\n",
      "|    reward             | -1.7947876 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 4.44       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 549      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 26.3     |\n",
      "|    reward             | 1.126185 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.538    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 41.3       |\n",
      "|    reward             | -1.5093899 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 60         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 567        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | 55.8       |\n",
      "|    reward             | 0.29027587 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 2.8        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 573       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -78.1     |\n",
      "|    reward             | 5.1948047 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 12.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 583       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 7.26      |\n",
      "|    reward             | 0.2690911 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0616    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 589        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -34.5      |\n",
      "|    reward             | 0.09704677 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.696      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 72         |\n",
      "|    reward             | -1.0637515 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 4.12       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 607      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -284     |\n",
      "|    reward             | 2.948475 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 55.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 615       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -25.3     |\n",
      "|    reward             | 3.2265134 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 2.78      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 622       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 34.3      |\n",
      "|    reward             | 1.6018704 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.27      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 61          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 631         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | -1.18       |\n",
      "|    reward             | 0.013757705 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 637        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | -0.182     |\n",
      "|    reward             | -0.7317939 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.0712     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 645       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -49.5     |\n",
      "|    reward             | 0.9202336 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.42      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 655        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -51.1      |\n",
      "|    reward             | 0.32330602 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.6        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 661       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -176      |\n",
      "|    reward             | 3.9807708 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 31.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 670        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.8      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -1.05e+03  |\n",
      "|    reward             | -6.0956445 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 708        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 61          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 676         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 0.164       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | -96.1       |\n",
      "|    reward             | -0.54658353 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 8.1         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 685        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.8      |\n",
      "|    explained_variance | 0.322      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | -46.6      |\n",
      "|    reward             | -0.2206827 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 694      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.284    |\n",
      "|    reward             | 1.638819 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.299    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 703      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -33.1    |\n",
      "|    reward             | 1.487439 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.31     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 709       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 0.00745   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -173      |\n",
      "|    reward             | 3.1066616 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 20.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 718       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 194       |\n",
      "|    reward             | -4.730858 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 43.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 724       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -0.0334   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 65.8      |\n",
      "|    reward             | 1.4894711 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.43      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 733        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 93.7       |\n",
      "|    reward             | -0.5122968 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 4.8        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 61          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 742         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | -48.2       |\n",
      "|    reward             | 0.037780657 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 749       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 39.1      |\n",
      "|    reward             | -0.753926 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 758       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 150       |\n",
      "|    reward             | 2.2911668 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 764      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 60.4     |\n",
      "|    reward             | 1.652799 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 28.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 774       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 13.2      |\n",
      "|    reward             | 0.3117458 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.367     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 61          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 782         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43         |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 17.5        |\n",
      "|    reward             | -0.11562487 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.556       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 791        |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 36.2       |\n",
      "|    reward             | -1.2007029 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 797       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -194      |\n",
      "|    reward             | -0.755971 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 21.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 806        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | -10.8      |\n",
      "|    reward             | -1.7145721 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.55       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 61         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 813        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | -21.2      |\n",
      "|    reward             | -4.7046494 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.92       |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=TIMESTEPS[0]) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Agent 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2YadjfnLwgt",
    "outputId": "883736bb-5b14-4306-816f-b7596b90275d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCDa78rqfO_a",
    "outputId": "c9962d70-9180-4377-daa7-0ae7363b8091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2956, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5442983.33\n",
      "total_reward: 4442983.33\n",
      "total_cost: 1749.20\n",
      "total_trades: 36503\n",
      "Sharpe: 0.890\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 24         |\n",
      "|    time_elapsed    | 491        |\n",
      "|    total_timesteps | 11828      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 8.32       |\n",
      "|    critic_loss     | 55.7       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 8871       |\n",
      "|    reward          | -7.7807484 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 21         |\n",
      "|    time_elapsed    | 1104       |\n",
      "|    total_timesteps | 23656      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 0.904      |\n",
      "|    critic_loss     | 4.34       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 20699      |\n",
      "|    reward          | -7.7807484 |\n",
      "-----------------------------------\n",
      "day: 2956, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4945534.62\n",
      "total_reward: 3945534.62\n",
      "total_cost: 999.00\n",
      "total_trades: 38403\n",
      "Sharpe: 0.813\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 20         |\n",
      "|    time_elapsed    | 1727       |\n",
      "|    total_timesteps | 35484      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -4.02      |\n",
      "|    critic_loss     | 2.49       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 32527      |\n",
      "|    reward          | -7.7807484 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 20         |\n",
      "|    time_elapsed    | 2359       |\n",
      "|    total_timesteps | 47312      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -7.06      |\n",
      "|    critic_loss     | 1.67       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 44355      |\n",
      "|    reward          | -7.7807484 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=TIMESTEPS[1]) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Agent 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5D5PFUhMzSV",
    "outputId": "01b7bbbb-7dce-4370-fe61-9098d4e5e978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt8eIQKYM4G3",
    "outputId": "54235862-b58b-4bd0-db25-1c62931703e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 62        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 32        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 1.9690489 |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014264977 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.85        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    reward               | -0.23267356 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013272027 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00327     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    reward               | 2.0128894   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018971011 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.0066      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | 1.8397616   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 162        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01756508 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.3      |\n",
      "|    explained_variance   | -0.0379    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.35       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0276    |\n",
      "|    reward               | -1.9081799 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 16.1       |\n",
      "----------------------------------------\n",
      "day: 2956, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3774977.58\n",
      "total_reward: 2774977.58\n",
      "total_cost: 401887.21\n",
      "total_trades: 81671\n",
      "Sharpe: 0.753\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026475038 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    reward               | 0.057799082 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018429227 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.00545    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | 1.7880479   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021180721 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.84        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | -2.2737408  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02675029 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.6      |\n",
      "|    explained_variance   | -0.00406   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.41       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    reward               | 0.98894453 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 40.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021093076 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.00926     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    reward               | -1.6284031  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020121586 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.000924    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    reward               | 0.22854926  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019215219 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | -0.00472    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.42        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    reward               | 0.4193624   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0126833   |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0292      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | -0.13859338 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023029715 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0295      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    reward               | 3.8744738   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024224166 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.35        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    reward               | -0.26325637 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 520         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018783428 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.0388      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | 0.24681076  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024655312 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | -0.007      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    reward               | -1.8455201  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019520486 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | -0.0287     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.11        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    reward               | -3.1618273  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027095716 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.0527      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.31        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    reward               | -0.55852425 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 651        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02232542 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.2      |\n",
      "|    explained_variance   | -0.0103    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.8       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0244    |\n",
      "|    reward               | -2.0887594 |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 29.7       |\n",
      "----------------------------------------\n",
      "day: 2956, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2970639.96\n",
      "total_reward: 1970639.96\n",
      "total_cost: 343994.69\n",
      "total_trades: 77702\n",
      "Sharpe: 0.613\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030464383 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.84        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | -0.31706023 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 718         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025304668 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | -0.0297     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.7         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    reward               | -0.2382796  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 748         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026483834 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | -0.00439    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.91        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    reward               | -1.159043   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 781         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027692135 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | -0.00753    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.84        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | 0.2796967   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 814         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023373984 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.9         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    reward               | 1.1403084   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.83        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=TIMESTEPS[2]) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSAHhV4Xc-bh",
    "outputId": "b0762c2c-09b6-4351-876a-59cd08be4707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/td3\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSRxNYAxdKpU",
    "outputId": "31b518ef-3966-413c-89f9-d83a037e55b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 24         |\n",
      "|    time_elapsed    | 485        |\n",
      "|    total_timesteps | 11828      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -18.2      |\n",
      "|    critic_loss     | 3.05e+03   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 8871       |\n",
      "|    reward          | -5.4769893 |\n",
      "-----------------------------------\n",
      "day: 2956, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3288091.49\n",
      "total_reward: 2288091.49\n",
      "total_cost: 1185.23\n",
      "total_trades: 59158\n",
      "Sharpe: 0.619\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 21         |\n",
      "|    time_elapsed    | 1092       |\n",
      "|    total_timesteps | 23656      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 9.12       |\n",
      "|    critic_loss     | 83.9       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 20699      |\n",
      "|    reward          | -5.4769893 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 20         |\n",
      "|    time_elapsed    | 1711       |\n",
      "|    total_timesteps | 35484      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 12.4       |\n",
      "|    critic_loss     | 6.69       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 32527      |\n",
      "|    reward          | -5.4769893 |\n",
      "-----------------------------------\n",
      "day: 2956, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3288091.49\n",
      "total_reward: 2288091.49\n",
      "total_cost: 1185.23\n",
      "total_trades: 59158\n",
      "Sharpe: 0.619\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 20         |\n",
      "|    time_elapsed    | 2337       |\n",
      "|    total_timesteps | 47312      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 15.4       |\n",
      "|    critic_loss     | 22         |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 44355      |\n",
      "|    reward          | -5.4769893 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=TIMESTEPS[3]) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwOhVjqRkCdM",
    "outputId": "a5ebf4e2-34ca-4bf5-8980-08d37a0659e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n",
      "Logging to results/sac\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8RSdKCckJyH",
    "outputId": "7f1e46f5-7124-4b6d-8fe7-f8071760cfe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 19         |\n",
      "|    time_elapsed    | 599        |\n",
      "|    total_timesteps | 11828      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 267        |\n",
      "|    critic_loss     | 20.6       |\n",
      "|    ent_coef        | 0.0815     |\n",
      "|    ent_coef_loss   | -114       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 11727      |\n",
      "|    reward          | -3.5861566 |\n",
      "-----------------------------------\n",
      "day: 2956, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3861827.22\n",
      "total_reward: 2861827.22\n",
      "total_cost: 18573.40\n",
      "total_trades: 51384\n",
      "Sharpe: 0.753\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 19        |\n",
      "|    time_elapsed    | 1215      |\n",
      "|    total_timesteps | 23656     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 105       |\n",
      "|    critic_loss     | 28.3      |\n",
      "|    ent_coef        | 0.0251    |\n",
      "|    ent_coef_loss   | -160      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 23555     |\n",
      "|    reward          | -3.716044 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 19        |\n",
      "|    time_elapsed    | 1838      |\n",
      "|    total_timesteps | 35484     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 49.8      |\n",
      "|    critic_loss     | 37.6      |\n",
      "|    ent_coef        | 0.00776   |\n",
      "|    ent_coef_loss   | -193      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 35383     |\n",
      "|    reward          | -4.683935 |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 19         |\n",
      "|    time_elapsed    | 2468       |\n",
      "|    total_timesteps | 47312      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 31.3       |\n",
      "|    critic_loss     | 2.79       |\n",
      "|    ent_coef        | 0.00247    |\n",
      "|    ent_coef_loss   | -155       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 47211      |\n",
      "|    reward          | -3.3984547 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=TIMESTEPS[4]) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## In-sample Performance\n",
    "\n",
    "Assume that the initial capital is $1,000,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data. If current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHZMBpSqh1jG",
    "outputId": "ffa57923-17e2-436e-c970-fcc52112a098"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2957.000000\n",
       "mean       18.105293\n",
       "std         7.272476\n",
       "min         9.140000\n",
       "25%        13.370000\n",
       "50%        16.209999\n",
       "75%        20.629999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDkszkMloRWT",
    "outputId": "7c539b2c-6223-4d00-d571-7af992f976bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.212001831054636"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AL7hs7svnNWT",
    "outputId": "6510973a-cfd3-4ff8-f482-287ac99de05c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2957.000000\n",
       "mean       34.139586\n",
       "std        43.879103\n",
       "min         0.000000\n",
       "25%        14.613449\n",
       "50%        23.644963\n",
       "75%        38.292666\n",
       "max       652.505968\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N78hfHckoqJ9",
    "outputId": "7258129e-a14b-4327-cb7e-f7cfb73b3dd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291.7261025697854"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trading (Out-of-sample Performance)\n",
    "\n",
    "We update periodically in order to take full advantage of the data, e.g., retrain quarterly, monthly or weekly. We also tune the parameters along the way, in this notebook we use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = insample_risk_indicator.turbulence.quantile(0.9),risk_indicator_col='turbulence', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "W_XNgGsBMeVw",
    "outputId": "37dba890-811e-4c0c-fee9-f12f3f9eb100"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fede4fa5-c07d-4b25-bc95-525a3a2500e1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>141.899994</td>\n",
       "      <td>142.919998</td>\n",
       "      <td>139.110001</td>\n",
       "      <td>141.404266</td>\n",
       "      <td>94639600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.703487</td>\n",
       "      <td>155.382845</td>\n",
       "      <td>137.132192</td>\n",
       "      <td>46.927735</td>\n",
       "      <td>-142.190143</td>\n",
       "      <td>41.749873</td>\n",
       "      <td>147.171798</td>\n",
       "      <td>146.269416</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>213.589996</td>\n",
       "      <td>214.610001</td>\n",
       "      <td>210.800003</td>\n",
       "      <td>203.845886</td>\n",
       "      <td>2629400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.097331</td>\n",
       "      <td>212.767983</td>\n",
       "      <td>199.379593</td>\n",
       "      <td>40.408568</td>\n",
       "      <td>-96.756949</td>\n",
       "      <td>36.189244</td>\n",
       "      <td>208.480831</td>\n",
       "      <td>217.103342</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>168.500000</td>\n",
       "      <td>175.119995</td>\n",
       "      <td>168.479996</td>\n",
       "      <td>170.695389</td>\n",
       "      <td>3956000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.281748</td>\n",
       "      <td>174.864263</td>\n",
       "      <td>149.785746</td>\n",
       "      <td>56.265103</td>\n",
       "      <td>117.565552</td>\n",
       "      <td>15.667511</td>\n",
       "      <td>161.812905</td>\n",
       "      <td>164.064442</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>222.850006</td>\n",
       "      <td>226.720001</td>\n",
       "      <td>220.600006</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>9113600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.730320</td>\n",
       "      <td>226.909442</td>\n",
       "      <td>205.727561</td>\n",
       "      <td>51.614047</td>\n",
       "      <td>116.649440</td>\n",
       "      <td>2.027170</td>\n",
       "      <td>217.175334</td>\n",
       "      <td>221.968500</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>192.899994</td>\n",
       "      <td>195.869995</td>\n",
       "      <td>191.240005</td>\n",
       "      <td>187.928040</td>\n",
       "      <td>3695500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.640323</td>\n",
       "      <td>205.735917</td>\n",
       "      <td>181.432778</td>\n",
       "      <td>41.999441</td>\n",
       "      <td>-112.087750</td>\n",
       "      <td>36.203176</td>\n",
       "      <td>196.993865</td>\n",
       "      <td>200.522105</td>\n",
       "      <td>21.1</td>\n",
       "      <td>120.122917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fede4fa5-c07d-4b25-bc95-525a3a2500e1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fede4fa5-c07d-4b25-bc95-525a3a2500e1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fede4fa5-c07d-4b25-bc95-525a3a2500e1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         date   tic        open        high         low       close  \\\n",
       "0  2021-10-01  AAPL  141.899994  142.919998  139.110001  141.404266   \n",
       "0  2021-10-01  AMGN  213.589996  214.610001  210.800003  203.845886   \n",
       "0  2021-10-01   AXP  168.500000  175.119995  168.479996  170.695389   \n",
       "0  2021-10-01    BA  222.850006  226.720001  220.600006  226.000000   \n",
       "0  2021-10-01   CAT  192.899994  195.869995  191.240005  187.928040   \n",
       "\n",
       "       volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
       "0  94639600.0  4.0 -1.703487  155.382845  137.132192  46.927735 -142.190143   \n",
       "0   2629400.0  4.0 -3.097331  212.767983  199.379593  40.408568  -96.756949   \n",
       "0   3956000.0  4.0  2.281748  174.864263  149.785746  56.265103  117.565552   \n",
       "0   9113600.0  4.0  0.730320  226.909442  205.727561  51.614047  116.649440   \n",
       "0   3695500.0  4.0 -3.640323  205.735917  181.432778  41.999441 -112.087750   \n",
       "\n",
       "       dx_30  close_30_sma  close_60_sma   vix  turbulence  \n",
       "0  41.749873    147.171798    146.269416  21.1  120.122917  \n",
       "0  36.189244    208.480831    217.103342  21.1  120.122917  \n",
       "0  15.667511    161.812905    164.064442  21.1  120.122917  \n",
       "0   2.027170    217.175334    221.968500  21.1  120.122917  \n",
       "0  36.203176    196.993865    200.522105  21.1  120.122917  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbFchno5j3xs",
    "outputId": "7eb7fa24-50a8-4506-97bf-a463e66f9102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_a2c\n",
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbYljWGjj3pH",
    "outputId": "3e682898-d5a5-4664-9469-77b6029cc277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_ddpg\n",
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74jNP2DBj3hb",
    "outputId": "d5f85887-a738-4699-e886-77d2225dd7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_ppo\n",
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7VyGGJPj3SH",
    "outputId": "10165564-7775-4358-c137-7c4ae646df6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_td3\n",
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLOnL5eYh1jR",
    "outputId": "6bdc3498-93b4-42ea-82ff-47ef9e99329c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_sac\n",
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERxw3KqLkcP4",
    "outputId": "52dbeacc-617a-4553-d4a9-8692b988a240"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_a2c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtesting Results\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeDeGAc9VrEg",
    "outputId": "11fb5805-7b2a-44c6-ccff-5238114632aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "\r[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (354, 8)\n",
      "Annual return         -0.034876\n",
      "Cumulative returns    -0.048644\n",
      "Annual volatility      0.181612\n",
      "Sharpe ratio          -0.105351\n",
      "Calmar ratio          -0.158953\n",
      "Stability              0.280983\n",
      "Max drawdown          -0.219408\n",
      "Omega ratio            0.982546\n",
      "Sortino ratio         -0.146974\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.970602\n",
      "Daily value at risk   -0.022957\n",
      "dtype: float64\n",
      "result:                       a2c          ddpg           td3           ppo  \\\n",
      "2021-10-26  1.051812e+06  1.018527e+06  1.056433e+06  1.011904e+06   \n",
      "2021-10-27  1.043241e+06  1.014168e+06  1.047235e+06  1.009184e+06   \n",
      "2021-10-28  1.052310e+06  1.022907e+06  1.054719e+06  1.015529e+06   \n",
      "2021-10-29  1.055662e+06  1.027023e+06  1.057137e+06  1.014713e+06   \n",
      "2021-11-01  1.057257e+06  1.032846e+06  1.060964e+06  1.018755e+06   \n",
      "...                  ...           ...           ...           ...   \n",
      "2023-02-21  1.041167e+06  9.991659e+05  1.026943e+06  9.549536e+05   \n",
      "2023-02-22  1.037622e+06  9.960402e+05  1.022617e+06  9.520512e+05   \n",
      "2023-02-23  1.038932e+06  9.987703e+05  1.026913e+06  9.537116e+05   \n",
      "2023-02-24  1.028207e+06  9.827645e+05  1.016881e+06  9.479264e+05   \n",
      "2023-02-27  1.030205e+06  9.877202e+05  1.018708e+06  9.499940e+05   \n",
      "\n",
      "                     sac      mean var           dji  \n",
      "2021-10-26  1.032124e+06  1.002272e+06  1.041671e+06  \n",
      "2021-10-27  1.025997e+06  1.002461e+06  1.033916e+06  \n",
      "2021-10-28  1.032015e+06  1.011236e+06  1.040902e+06  \n",
      "2021-10-29  1.032366e+06  1.010909e+06  1.043497e+06  \n",
      "2021-11-01  1.035971e+06  1.001450e+06  1.046244e+06  \n",
      "...                  ...           ...           ...  \n",
      "2023-02-21  9.249436e+05  9.195315e+05  9.651327e+05  \n",
      "2023-02-22  9.238542e+05  9.194654e+05  9.626710e+05  \n",
      "2023-02-23  9.251586e+05  9.249119e+05  9.658412e+05  \n",
      "2023-02-24  9.190799e+05  9.120101e+05  9.560240e+05  \n",
      "2023-02-27  9.207091e+05  9.135293e+05  9.581264e+05  \n",
      "\n",
      "[336 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-83-8649fecf2458>:23: FutureWarning: Passing 'suffixes' which cause duplicate columns {'account_value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  result = pd.merge(result, df_result_ppo, left_index=True, right_index=True)\n",
      "<ipython-input-83-8649fecf2458>:26: FutureWarning: Passing 'suffixes' which cause duplicate columns {'account_value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  result = pd.merge(result, df_dji, left_index=True, right_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
    "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
    "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
    "df_account_value_a2c.to_csv(\"results/df_account_value_a2c.csv\")\n",
    "df_account_value_ddpg.to_csv(\"results/df_account_value_ddpg.csv\")\n",
    "df_account_value_td3.to_csv(\"results/df_account_value_td3.csv\")\n",
    "df_account_value_ppo.to_csv(\"results/df_account_value_ppo.csv\")\n",
    "df_account_value_sac.to_csv(\"results/df_account_value_sac.csv\")\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "df_dji_ = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = TRADE_START_DATE,\n",
    "        end = TRADE_END_DATE)\n",
    "stats = backtest_stats(df_dji_, value_col_name = 'close')\n",
    "df_dji = pd.DataFrame()\n",
    "df_dji['date'] = df_account_value_a2c['date']\n",
    "df_dji['account_value'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "df_dji.to_csv(\"results/df_dji.csv\")\n",
    "df_dji = df_dji.set_index(df_dji.columns[0])\n",
    "df_dji.to_csv(\"results/df_dji+.csv\")\n",
    "\n",
    "result = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_td3, left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_ppo, left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_sac, left_index=True, right_index=True)\n",
    "# result = pd.merge(result, MVO_result, left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_dji, left_index=True, right_index=True)\n",
    "result.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'dji']\n",
    "\n",
    "print(\"result: \", result)\n",
    "result.to_csv(\"results/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "6xRfrqK4RVfq",
    "outputId": "42a2502d-7447-40ef-e897-1af949fda9e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "fig = plt.figure()\n",
    "result.plot()\n",
    "fig.savefig('backtest.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ThinkPad\\\\Desktop\\\\code\\\\FinRL\\\\results.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "folder_name = 'results'\n",
    "zip_file_name = 'results'\n",
    "shutil.make_archive(zip_file_name, 'zip', folder_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HMNR5nHjh1iz",
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "54cefccbf0f07c9750f12aa115c023dfa5ed4acecf9e7ad3bc9391869be60d0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
